{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd08a5-c6c2-4b50-81f8-29e87fa27dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r \"../requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447348e-a407-4a58-81a4-f33958dc47ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3eab62-9dc8-414d-9f59-582038fc59cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from heroic_gm.models.heroic_nn import HeroicScoreNet\n",
    "from heroic_gm.data.heroic_dataset import HeroicDataset\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa2979-897a-4f67-89ac-e2a966cd0557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FROM_CHECKPOINT=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ecbb1-11bb-4843-ab17-9021d2a7ddc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PARQUET_DATABASE_URL=\"https://huggingface.co/datasets/0xJustin/Dungeons-and-Diffusion/resolve/main/data/train-00000-of-00001-9b40395dcd3257f2.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b6f6d-f5dd-42ba-818b-343fd165ccd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Yang Song notebook\n",
    "device = 'cuda'\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:    \n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.  \n",
    "  \n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"    \n",
    "  t = torch.tensor(t, device=device)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "  \n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "  \n",
    "sigma =  25.0\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0107d72-ba0d-4a72-9e4e-66664b14b258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Yang Song notebook\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a \n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.    \n",
    "    marginal_prob_std: A function that gives the standard deviation of \n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t)\n",
    "  perturbed_x = x + z * std[:, None, None, None]\n",
    "  score = model(perturbed_x, random_t)\n",
    "  loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f4868-9a71-4033-9dc4-03bfef6ff627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Yang Song notebook\n",
    "\n",
    "score_model = torch.nn.DataParallel(HeroicScoreNet(marginal_prob_std=marginal_prob_std_fn, channels=[64, 128, 256, 512],embed_dim=512))\n",
    "score_model = score_model.to(device)\n",
    "\n",
    "if FROM_CHECKPOINT:\n",
    "    score_model.load_state_dict(torch.load('ckpt.pth',map_location=device))\n",
    "\n",
    "n_epochs =   50 \n",
    "## size of a mini-batch\n",
    "batch_size =  8\n",
    "## learning rate\n",
    "lr=1e-4 \n",
    "\n",
    "dataset = HeroicDataset(PARQUET_DATABASE_URL)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1,pin_memory=True)\n",
    "\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "tqdm_epoch = tqdm.trange(n_epochs)\n",
    "for epoch in tqdm_epoch:\n",
    "  avg_loss = 0.\n",
    "  num_items = 0\n",
    "  for _, y in data_loader:\n",
    "    y = y.to(device)    \n",
    "    loss = loss_fn(score_model, y, marginal_prob_std_fn)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    avg_loss += loss.item() * y.shape[0]\n",
    "    num_items += y.shape[0]\n",
    "  # Print the averaged training loss so far.\n",
    "  print('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "  # Update the checkpoint after each epoch of training.\n",
    "  torch.save(score_model.state_dict(), 'ckpt.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
