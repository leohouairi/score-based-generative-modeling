{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150f5e0-8e61-4a4a-bc09-bb7fde5cc374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r \"../requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fbace-e1e2-4cba-8cfd-4f27041d02ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ml-collections==0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c62e4-f717-4ce4-ac9a-598999b833a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecbef4-2053-4dab-ac38-35d2e3c94f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from heroic_gm.models.heroic_nn import HeroicScoreNet\n",
    "from heroic_gm.data.heroic_dataset import HeroicDataset\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf8052-8f6b-44a4-b803-c0889016778b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SDE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2bba9-caf6-42f7-b5e5-6f475435ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yang Song sde_lib class\n",
    "\"\"\"Abstract SDE classes, Reverse SDE, and VE/VP SDEs.\"\"\"\n",
    "import abc\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SDE(abc.ABC):\n",
    "  \"\"\"SDE abstract class. Functions are designed for a mini-batch of inputs.\"\"\"\n",
    "\n",
    "  def __init__(self, N):\n",
    "    \"\"\"Construct an SDE.\n",
    "\n",
    "    Args:\n",
    "      N: number of discretization time steps.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.N = N\n",
    "\n",
    "  @property\n",
    "  @abc.abstractmethod\n",
    "  def T(self):\n",
    "    \"\"\"End time of the SDE.\"\"\"\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def sde(self, x, t):\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def marginal_prob(self, x, t):\n",
    "    \"\"\"Parameters to determine the marginal distribution of the SDE, $p_t(x)$.\"\"\"\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def prior_sampling(self, shape):\n",
    "    \"\"\"Generate one sample from the prior distribution, $p_T(x)$.\"\"\"\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def prior_logp(self, z):\n",
    "    \"\"\"Compute log-density of the prior distribution.\n",
    "\n",
    "    Useful for computing the log-likelihood via probability flow ODE.\n",
    "\n",
    "    Args:\n",
    "      z: latent code\n",
    "    Returns:\n",
    "      log probability density\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "  def discretize(self, x, t):\n",
    "    \"\"\"Discretize the SDE in the form: x_{i+1} = x_i + f_i(x_i) + G_i z_i.\n",
    "\n",
    "    Useful for reverse diffusion sampling and probabiliy flow sampling.\n",
    "    Defaults to Euler-Maruyama discretization.\n",
    "\n",
    "    Args:\n",
    "      x: a torch tensor\n",
    "      t: a torch float representing the time step (from 0 to `self.T`)\n",
    "\n",
    "    Returns:\n",
    "      f, G\n",
    "    \"\"\"\n",
    "    dt = 1 / self.N\n",
    "    drift, diffusion = self.sde(x, t)\n",
    "    f = drift * dt\n",
    "    G = diffusion * torch.sqrt(torch.tensor(dt, device=t.device))\n",
    "    return f, G\n",
    "\n",
    "  def reverse(self, score_fn, probability_flow=False):\n",
    "    \"\"\"Create the reverse-time SDE/ODE.\n",
    "\n",
    "    Args:\n",
    "      score_fn: A time-dependent score-based model that takes x and t and returns the score.\n",
    "      probability_flow: If `True`, create the reverse-time ODE used for probability flow sampling.\n",
    "    \"\"\"\n",
    "    N = self.N\n",
    "    T = self.T\n",
    "    sde_fn = self.sde\n",
    "    discretize_fn = self.discretize\n",
    "\n",
    "    # Build the class for reverse-time SDE.\n",
    "    class RSDE(self.__class__):\n",
    "      def __init__(self):\n",
    "        self.N = N\n",
    "        self.probability_flow = probability_flow\n",
    "\n",
    "      @property\n",
    "      def T(self):\n",
    "        return T\n",
    "\n",
    "      def sde(self, x, t):\n",
    "        \"\"\"Create the drift and diffusion functions for the reverse SDE/ODE.\"\"\"\n",
    "        drift, diffusion = sde_fn(x, t)\n",
    "        score = score_fn(x, t)\n",
    "        drift = drift - diffusion[:, None, None, None] ** 2 * score * (0.5 if self.probability_flow else 1.)\n",
    "        # Set the diffusion function to zero for ODEs.\n",
    "        diffusion = 0. if self.probability_flow else diffusion\n",
    "        return drift, diffusion\n",
    "\n",
    "      def discretize(self, x, t):\n",
    "        \"\"\"Create discretized iteration rules for the reverse diffusion sampler.\"\"\"\n",
    "        f, G = discretize_fn(x, t)\n",
    "        rev_f = f - G[:, None, None, None] ** 2 * score_fn(x, t) * (0.5 if self.probability_flow else 1.)\n",
    "        rev_G = torch.zeros_like(G) if self.probability_flow else G\n",
    "        return rev_f, rev_G\n",
    "\n",
    "    return RSDE()\n",
    "\n",
    "\n",
    "class VPSDE(SDE):\n",
    "  def __init__(self, beta_min=0.1, beta_max=20, N=1000):\n",
    "    \"\"\"Construct a Variance Preserving SDE.\n",
    "\n",
    "    Args:\n",
    "      beta_min: value of beta(0)\n",
    "      beta_max: value of beta(1)\n",
    "      N: number of discretization steps\n",
    "    \"\"\"\n",
    "    super().__init__(N)\n",
    "    self.beta_0 = beta_min\n",
    "    self.beta_1 = beta_max\n",
    "    self.N = N\n",
    "    self.discrete_betas = torch.linspace(beta_min / N, beta_max / N, N)\n",
    "    self.alphas = 1. - self.discrete_betas\n",
    "    self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "    self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "    self.sqrt_1m_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n",
    "\n",
    "  @property\n",
    "  def T(self):\n",
    "    return 1\n",
    "\n",
    "  def sde(self, x, t):\n",
    "    beta_t = self.beta_0 + t * (self.beta_1 - self.beta_0)\n",
    "    drift = -0.5 * beta_t[:, None, None, None] * x\n",
    "    diffusion = torch.sqrt(beta_t)\n",
    "    return drift, diffusion\n",
    "\n",
    "  def marginal_prob(self, x, t):\n",
    "    log_mean_coeff = -0.25 * t ** 2 * (self.beta_1 - self.beta_0) - 0.5 * t * self.beta_0\n",
    "    mean = torch.exp(log_mean_coeff[:, None, None, None]) * x\n",
    "    std = torch.sqrt(1. - torch.exp(2. * log_mean_coeff))\n",
    "    return mean, std\n",
    "\n",
    "  def prior_sampling(self, shape):\n",
    "    return torch.randn(*shape)\n",
    "\n",
    "  def prior_logp(self, z):\n",
    "    shape = z.shape\n",
    "    N = np.prod(shape[1:])\n",
    "    logps = -N / 2. * np.log(2 * np.pi) - torch.sum(z ** 2, dim=(1, 2, 3)) / 2.\n",
    "    return logps\n",
    "\n",
    "  def discretize(self, x, t):\n",
    "    \"\"\"DDPM discretization.\"\"\"\n",
    "    timestep = (t * (self.N - 1) / self.T).long()\n",
    "    beta = self.discrete_betas.to(x.device)[timestep]\n",
    "    alpha = self.alphas.to(x.device)[timestep]\n",
    "    sqrt_beta = torch.sqrt(beta)\n",
    "    f = torch.sqrt(alpha)[:, None, None, None] * x - x\n",
    "    G = sqrt_beta\n",
    "    return f, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fa52b-108a-4141-ad20-6abd8d5f2711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_fn(model, train=False):\n",
    "  \"\"\"Create a function to give the output of the score-based model.\n",
    "\n",
    "  Args:\n",
    "    model: The score model.\n",
    "    train: `True` for training and `False` for evaluation.\n",
    "\n",
    "  Returns:\n",
    "    A model function.\n",
    "  \"\"\"\n",
    "\n",
    "  def model_fn(x, labels):\n",
    "    \"\"\"Compute the output of the score-based model.\n",
    "\n",
    "    Args:\n",
    "      x: A mini-batch of input data.\n",
    "      labels: A mini-batch of conditioning variables for time steps. Should be interpreted differently\n",
    "        for different models.\n",
    "\n",
    "    Returns:\n",
    "      A tuple of (model output, new mutable states)\n",
    "    \"\"\"\n",
    "    if not train:\n",
    "      model.eval()\n",
    "      return model(x, labels)\n",
    "    else:\n",
    "      model.train()\n",
    "      return model(x, labels)\n",
    "\n",
    "  return model_fn\n",
    "\n",
    "\n",
    "def get_score_fn(sde, model, train=False, continuous=False):\n",
    "    \"\"\"Wraps `score_fn` so that the model output corresponds to a real time-dependent score function.\n",
    "\n",
    "    Args:\n",
    "    sde: An `sde_lib.SDE` object that represents the forward SDE.\n",
    "    model: A score model.\n",
    "    train: `True` for training and `False` for evaluation.\n",
    "    continuous: If `True`, the score-based model is expected to directly take continuous time steps.\n",
    "\n",
    "    Returns:\n",
    "    A score function.\n",
    "    \"\"\"\n",
    "    model_fn = get_model_fn(model, train=train)\n",
    "\n",
    "    def score_fn(x, t):\n",
    "        # For VP-trained models, t=0 corresponds to the lowest noise level\n",
    "        labels = t * (sde.N - 1)\n",
    "        score = model_fn(x, labels)\n",
    "        std = sde.sqrt_1m_alphas_cumprod.to(labels.device)[labels.long()]\n",
    "\n",
    "        score = -score / std[:, None, None, None]\n",
    "        return score\n",
    "\n",
    "    return score_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde56164-63ad-4e66-9c07-564f9063a703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import functools\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.act = act = get_act(config)\n",
    "    self.register_buffer('sigmas', torch.tensor(utils.get_sigmas(config)))\n",
    "\n",
    "    self.nf = nf = config.model.nf\n",
    "    ch_mult = config.model.ch_mult\n",
    "    self.num_res_blocks = num_res_blocks = config.model.num_res_blocks\n",
    "    self.attn_resolutions = attn_resolutions = config.model.attn_resolutions\n",
    "    dropout = config.model.dropout\n",
    "    resamp_with_conv = config.model.resamp_with_conv\n",
    "    self.num_resolutions = num_resolutions = len(ch_mult)\n",
    "    self.all_resolutions = all_resolutions = [config.data.image_size // (2 ** i) for i in range(num_resolutions)]\n",
    "\n",
    "    AttnBlock = functools.partial(layers.AttnBlock)\n",
    "    self.conditional = conditional = config.model.conditional\n",
    "    ResnetBlock = functools.partial(ResnetBlockDDPM, act=act, temb_dim=4 * nf, dropout=dropout)\n",
    "    if conditional:\n",
    "      # Condition on noise levels.\n",
    "      modules = [nn.Linear(nf, nf * 4)]\n",
    "      modules[0].weight.data = default_initializer()(modules[0].weight.data.shape)\n",
    "      nn.init.zeros_(modules[0].bias)\n",
    "      modules.append(nn.Linear(nf * 4, nf * 4))\n",
    "      modules[1].weight.data = default_initializer()(modules[1].weight.data.shape)\n",
    "      nn.init.zeros_(modules[1].bias)\n",
    "\n",
    "    self.centered = config.data.centered\n",
    "    channels = config.data.num_channels\n",
    "\n",
    "    # Downsampling block\n",
    "    modules.append(conv3x3(channels, nf))\n",
    "    hs_c = [nf]\n",
    "    in_ch = nf\n",
    "    for i_level in range(num_resolutions):\n",
    "      # Residual blocks for this resolution\n",
    "      for i_block in range(num_res_blocks):\n",
    "        out_ch = nf * ch_mult[i_level]\n",
    "        modules.append(ResnetBlock(in_ch=in_ch, out_ch=out_ch))\n",
    "        in_ch = out_ch\n",
    "        if all_resolutions[i_level] in attn_resolutions:\n",
    "          modules.append(AttnBlock(channels=in_ch))\n",
    "        hs_c.append(in_ch)\n",
    "      if i_level != num_resolutions - 1:\n",
    "        modules.append(Downsample(channels=in_ch, with_conv=resamp_with_conv))\n",
    "        hs_c.append(in_ch)\n",
    "\n",
    "    in_ch = hs_c[-1]\n",
    "    modules.append(ResnetBlock(in_ch=in_ch))\n",
    "    modules.append(AttnBlock(channels=in_ch))\n",
    "    modules.append(ResnetBlock(in_ch=in_ch))\n",
    "\n",
    "    # Upsampling block\n",
    "    for i_level in reversed(range(num_resolutions)):\n",
    "      for i_block in range(num_res_blocks + 1):\n",
    "        out_ch = nf * ch_mult[i_level]\n",
    "        modules.append(ResnetBlock(in_ch=in_ch + hs_c.pop(), out_ch=out_ch))\n",
    "        in_ch = out_ch\n",
    "      if all_resolutions[i_level] in attn_resolutions:\n",
    "        modules.append(AttnBlock(channels=in_ch))\n",
    "      if i_level != 0:\n",
    "        modules.append(Upsample(channels=in_ch, with_conv=resamp_with_conv))\n",
    "\n",
    "    assert not hs_c\n",
    "    modules.append(nn.GroupNorm(num_channels=in_ch, num_groups=32, eps=1e-6))\n",
    "    modules.append(conv3x3(in_ch, channels, init_scale=0.))\n",
    "    self.all_modules = nn.ModuleList(modules)\n",
    "\n",
    "    self.scale_by_sigma = config.model.scale_by_sigma\n",
    "\n",
    "  def forward(self, x, labels):\n",
    "    modules = self.all_modules\n",
    "    m_idx = 0\n",
    "    if self.conditional:\n",
    "      # timestep/scale embedding\n",
    "      timesteps = labels\n",
    "      temb = layers.get_timestep_embedding(timesteps, self.nf)\n",
    "      temb = modules[m_idx](temb)\n",
    "      m_idx += 1\n",
    "      temb = modules[m_idx](self.act(temb))\n",
    "      m_idx += 1\n",
    "    else:\n",
    "      temb = None\n",
    "\n",
    "    if self.centered:\n",
    "      # Input is in [-1, 1]\n",
    "      h = x\n",
    "    else:\n",
    "      # Input is in [0, 1]\n",
    "      h = 2 * x - 1.\n",
    "\n",
    "    # Downsampling block\n",
    "    hs = [modules[m_idx](h)]\n",
    "    m_idx += 1\n",
    "    for i_level in range(self.num_resolutions):\n",
    "      # Residual blocks for this resolution\n",
    "      for i_block in range(self.num_res_blocks):\n",
    "        h = modules[m_idx](hs[-1], temb)\n",
    "        m_idx += 1\n",
    "        if h.shape[-1] in self.attn_resolutions:\n",
    "          h = modules[m_idx](h)\n",
    "          m_idx += 1\n",
    "        hs.append(h)\n",
    "      if i_level != self.num_resolutions - 1:\n",
    "        hs.append(modules[m_idx](hs[-1]))\n",
    "        m_idx += 1\n",
    "\n",
    "    h = hs[-1]\n",
    "    h = modules[m_idx](h, temb)\n",
    "    m_idx += 1\n",
    "    h = modules[m_idx](h)\n",
    "    m_idx += 1\n",
    "    h = modules[m_idx](h, temb)\n",
    "    m_idx += 1\n",
    "\n",
    "    # Upsampling block\n",
    "    for i_level in reversed(range(self.num_resolutions)):\n",
    "      for i_block in range(self.num_res_blocks + 1):\n",
    "        h = modules[m_idx](torch.cat([h, hs.pop()], dim=1), temb)\n",
    "        m_idx += 1\n",
    "      if h.shape[-1] in self.attn_resolutions:\n",
    "        h = modules[m_idx](h)\n",
    "        m_idx += 1\n",
    "      if i_level != 0:\n",
    "        h = modules[m_idx](h)\n",
    "        m_idx += 1\n",
    "\n",
    "    assert not hs\n",
    "    h = self.act(modules[m_idx](h))\n",
    "    m_idx += 1\n",
    "    h = modules[m_idx](h)\n",
    "    m_idx += 1\n",
    "    assert m_idx == len(modules)\n",
    "\n",
    "    if self.scale_by_sigma:\n",
    "      # Divide the output by sigmas. Useful for training with the NCSN loss.\n",
    "      # The DDPM loss scales the network output by sigma in the loss function,\n",
    "      # so no need of doing it here.\n",
    "      used_sigmas = self.sigmas[labels, None, None, None]\n",
    "      h = h / used_sigmas\n",
    "\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10462656-116c-4129-9753-e6a42397bac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_default_configs():\n",
    "  config = ml_collections.ConfigDict()\n",
    "  # training\n",
    "  config.training = training = ml_collections.ConfigDict()\n",
    "  config.training.batch_size = 128\n",
    "  training.n_iters = 1300001\n",
    "  training.snapshot_freq = 50000\n",
    "  training.log_freq = 50\n",
    "  training.eval_freq = 100\n",
    "  ## store additional checkpoints for preemption in cloud computing environments\n",
    "  training.snapshot_freq_for_preemption = 10000\n",
    "  ## produce samples at each snapshot.\n",
    "  training.snapshot_sampling = True\n",
    "  training.likelihood_weighting = False\n",
    "  training.continuous = False\n",
    "  training.reduce_mean = False\n",
    "\n",
    "  # sampling\n",
    "  config.sampling = sampling = ml_collections.ConfigDict()\n",
    "  sampling.n_steps_each = 1\n",
    "  sampling.noise_removal = True\n",
    "  sampling.probability_flow = False\n",
    "  sampling.snr = 0.17\n",
    "\n",
    "  # evaluation\n",
    "  config.eval = evaluate = ml_collections.ConfigDict()\n",
    "  evaluate.begin_ckpt = 1\n",
    "  evaluate.end_ckpt = 26\n",
    "  evaluate.batch_size = 1024\n",
    "  evaluate.enable_sampling = True\n",
    "  evaluate.num_samples = 50000\n",
    "  evaluate.enable_loss = True\n",
    "  evaluate.enable_bpd = False\n",
    "  evaluate.bpd_dataset = 'test'\n",
    "\n",
    "  # data\n",
    "  config.data = data = ml_collections.ConfigDict()\n",
    "  data.dataset = 'DungeonDiffusion'\n",
    "  data.image_size = 512\n",
    "  data.random_flip = True\n",
    "  data.uniform_dequantization = False\n",
    "  data.centered = False\n",
    "  data.num_channels = 3\n",
    "\n",
    "  # model\n",
    "  config.model = model = ml_collections.ConfigDict()\n",
    "  model.sigma_max = 90.\n",
    "  model.sigma_min = 0.01\n",
    "  model.num_scales = 1000\n",
    "  model.beta_min = 0.1\n",
    "  model.beta_max = 20.\n",
    "  model.dropout = 0.1\n",
    "  model.embedding_type = 'fourier'\n",
    "\n",
    "  # optimization\n",
    "  config.optim = optim = ml_collections.ConfigDict()\n",
    "  optim.weight_decay = 0\n",
    "  optim.optimizer = 'Adam'\n",
    "  optim.lr = 2e-4\n",
    "  optim.beta1 = 0.9\n",
    "  optim.eps = 1e-8\n",
    "  optim.warmup = 5000\n",
    "  optim.grad_clip = 1.\n",
    "\n",
    "  config.seed = 42\n",
    "  config.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "  return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3719e-25cd-4de9-b36d-34a99ec5a8f4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38577e20-b3f2-4fc4-b859-473e27b6d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model.\n",
    "score_model = DDPM(get_default_configs())\n",
    "ema = ExponentialMovingAverage(score_model.parameters(), decay=config.model.ema_rate)\n",
    "optimizer = losses.get_optimizer(config, score_model.parameters())\n",
    "state = dict(optimizer=optimizer, model=score_model, ema=ema, step=0)\n",
    "\n",
    "# Create checkpoints directory\n",
    "#checkpoint_dir = os.path.join(workdir, \"checkpoints\")\n",
    "# Intermediate checkpoints to resume training after pre-emption in cloud environments\n",
    "#checkpoint_meta_dir = os.path.join(workdir, \"checkpoints-meta\", \"checkpoint.pth\")\n",
    "#tf.io.gfile.makedirs(checkpoint_dir)\n",
    "#tf.io.gfile.makedirs(os.path.dirname(checkpoint_meta_dir))\n",
    "# Resume training when intermediate checkpoints are detected\n",
    "#state = restore_checkpoint(checkpoint_meta_dir, state, config.device)\n",
    "initial_step = int(state['step'])\n",
    "\n",
    "# Build data iterators\n",
    "#train_ds, eval_ds, _ = datasets.get_dataset(config,\n",
    "#                                          uniform_dequantization=config.data.uniform_dequantization)\n",
    "#train_iter = iter(train_ds)  # pytype: disable=wrong-arg-types\n",
    "#eval_iter = iter(eval_ds)  # pytype: disable=wrong-arg-types\n",
    "# Create data normalizer and its inverse\n",
    "#scaler = datasets.get_data_scaler(config)\n",
    "#inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
    "\n",
    "# Setup SDEs\n",
    "sde = VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
    "sampling_eps = 1e-3\n",
    "\n",
    "# Build one-step training and evaluation functions\n",
    "optimize_fn = losses.optimization_manager(config)\n",
    "continuous = config.training.continuous\n",
    "reduce_mean = config.training.reduce_mean\n",
    "likelihood_weighting = config.training.likelihood_weighting\n",
    "train_step_fn = losses.get_step_fn(sde, train=True, optimize_fn=optimize_fn,\n",
    "                                 reduce_mean=reduce_mean, continuous=continuous,\n",
    "                                 likelihood_weighting=likelihood_weighting)\n",
    "eval_step_fn = losses.get_step_fn(sde, train=False, optimize_fn=optimize_fn,\n",
    "                                reduce_mean=reduce_mean, continuous=continuous,\n",
    "                                likelihood_weighting=likelihood_weighting)\n",
    "\n",
    "# Building sampling functions\n",
    "#if config.training.snapshot_sampling:\n",
    "#    sampling_shape = (config.training.batch_size, config.data.num_channels,\n",
    "#                      config.data.image_size, config.data.image_size)\n",
    "#    sampling_fn = sampling.get_sampling_fn(config, sde, sampling_shape, inverse_scaler, sampling_eps)\n",
    "\n",
    "num_train_steps = config.training.n_iters\n",
    "\n",
    "# In case there are multiple hosts (e.g., TPU pods), only log to host 0\n",
    "logging.info(\"Starting training loop at step %d.\" % (initial_step,))\n",
    "\n",
    "for step in range(initial_step, num_train_steps + 1):\n",
    "# Convert data to JAX arrays and normalize them. Use ._numpy() to avoid copy.\n",
    "batch = torch.from_numpy(next(train_iter)['image']._numpy()).to(config.device).float()\n",
    "batch = batch.permute(0, 3, 1, 2)\n",
    "batch = scaler(batch)\n",
    "# Execute one training step\n",
    "loss = train_step_fn(state, batch)\n",
    "if step % config.training.log_freq == 0:\n",
    "  print(\"step: %d, training_loss: %.5e\" % (step, loss.item()))\n",
    "  \n",
    "\n",
    "# Save a temporary checkpoint to resume training after pre-emption periodically\n",
    "#if step != 0 and step % config.training.snapshot_freq_for_preemption == 0:\n",
    "#  save_checkpoint(checkpoint_meta_dir, state)\n",
    "\n",
    "# Report the loss on an evaluation dataset periodically\n",
    "#if step % config.training.eval_freq == 0:\n",
    "#  eval_batch = torch.from_numpy(next(eval_iter)['image']._numpy()).to(config.device).float()\n",
    "#  eval_batch = eval_batch.permute(0, 3, 1, 2)\n",
    "#  eval_batch = scaler(eval_batch)\n",
    "#  eval_loss = eval_step_fn(state, eval_batch)\n",
    "#  logging.info(\"step: %d, eval_loss: %.5e\" % (step, eval_loss.item()))\n",
    "#  writer.add_scalar(\"eval_loss\", eval_loss.item(), step)\n",
    "\n",
    "# Save a checkpoint periodically and generate samples if needed\n",
    "#if step != 0 and step % config.training.snapshot_freq == 0 or step == num_train_steps:\n",
    "  # Save the checkpoint.\n",
    "#  save_step = step // config.training.snapshot_freq\n",
    "#  save_checkpoint(os.path.join(checkpoint_dir, f'checkpoint_{save_step}.pth'), state)\n",
    "\n",
    "  # Generate and save samples\n",
    "#  if config.training.snapshot_sampling:\n",
    "#    ema.store(score_model.parameters())\n",
    "#    ema.copy_to(score_model.parameters())\n",
    "#    sample, n = sampling_fn(score_model)\n",
    "#    ema.restore(score_model.parameters())\n",
    "#    this_sample_dir = os.path.join(sample_dir, \"iter_{}\".format(step))\n",
    "#    tf.io.gfile.makedirs(this_sample_dir)\n",
    "#    nrow = int(np.sqrt(sample.shape[0]))\n",
    "#    image_grid = make_grid(sample, nrow, padding=2)\n",
    "#    sample = np.clip(sample.permute(0, 2, 3, 1).cpu().numpy() * 255, 0, 255).astype(np.uint8)\n",
    "#    with tf.io.gfile.GFile(\n",
    "#        os.path.join(this_sample_dir, \"sample.np\"), \"wb\") as fout:\n",
    "#      np.save(fout, sample)\n",
    "\n",
    "#    with tf.io.gfile.GFile(\n",
    "#        os.path.join(this_sample_dir, \"sample.png\"), \"wb\") as fout:\n",
    "#      save_image(image_grid, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
